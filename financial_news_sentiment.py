# -*- coding: utf-8 -*-
"""financial_news_sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZZw2fcsKtX94735mpG31T4Eo_fH8oL02
"""

!pip install pandas numpy scikit-learn matplotlib seaborn

import pandas as pd
import numpy as np
import re

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="whitegrid")

df = pd.read_csv("/content/financial_news.csv", encoding='latin1')
df.head()

print(df.shape)
df.columns = ['sentiment', 'text']
print(df['sentiment'].value_counts())

def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-z\s]", "", text)
    return text

df["clean_text"] = df["text"].apply(clean_text)
df.head()

X = df["clean_text"]
y = df["sentiment"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

vectorizer = TfidfVectorizer(max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

model = LogisticRegression(max_iter=1000)
model.fit(X_train_vec, y_train)

y_pred = model.predict(X_test_vec)
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d")
plt.show()

!pip install transformers torch

from transformers import pipeline

sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

def llm_sentiment(text):
    result = sentiment_pipeline(text[:512])[0]  # limit length
    label = result["label"]

    if label == "POSITIVE":
        return "Positive"
    elif label == "NEGATIVE":
        return "Negative"
    else:
        return "Neutral"

sample_df = df.sample(50, random_state=42)

sample_df["llm_pred"] = sample_df["clean_text"].apply(llm_sentiment)
sample_df[["text", "sentiment", "llm_pred"]].head()

ALLOWED_LABELS = ["Positive", "Negative", "Neutral"]

def guardrail(label):
    if label not in ALLOWED_LABELS:
        return "Neutral"
    return label

sample_df["llm_pred"] = sample_df["llm_pred"].apply(guardrail)

from sklearn.metrics import accuracy_score

ml_preds_sample = model.predict(
    vectorizer.transform(sample_df["clean_text"])
)

print("ML Accuracy (sample):",
      accuracy_score(sample_df["sentiment"], ml_preds_sample))

print("LLM Accuracy (sample):",
      accuracy_score(sample_df["sentiment"], sample_df["llm_pred"]))

errors = sample_df[
    sample_df["sentiment"] != sample_df["llm_pred"]
]

errors[["text", "sentiment", "llm_pred"]].head(10)

def llm_sentiment_with_confidence(text, threshold=0.7):
    # Run the pipeline, limiting input length if needed
    result = sentiment_pipeline(text[:512])[0]  # e.g. {'label': 'POSITIVE', 'score': 0.95}
    label = result["label"]
    score = result["score"]

    # Map labels to your format
    if label == "POSITIVE":
        mapped_label = "Positive"
    elif label == "NEGATIVE":
        mapped_label = "Negative"
    else:
        mapped_label = "Neutral"

    # Apply confidence threshold guardrail
    if score < threshold:
        # Low confidence â†’ fallback to Neutral
        return "Neutral"

    return mapped_label

sample_df["llm_pred_conf"] = sample_df["clean_text"].apply(llm_sentiment_with_confidence)

print("Unique true labels:", sample_df["sentiment"].unique())
print("Unique original LLM predictions:", sample_df["llm_pred"].unique())
print("Unique guarded LLM predictions:", sample_df["llm_pred_conf"].unique())

true_labels = sample_df["sentiment"].str.lower()
original_preds = sample_df["llm_pred"].str.lower()
guarded_preds = sample_df["llm_pred_conf"].str.lower()

print("Original LLM Accuracy:",
      accuracy_score(true_labels, original_preds))

print("Guarded LLM Accuracy:",
      accuracy_score(true_labels, guarded_preds))

print(f"Sample size: {len(sample_df)}")

print(sample_df[["sentiment", "llm_pred", "llm_pred_conf"]].head(10))

from sklearn.metrics import accuracy_score

# Normalize all labels to lowercase for fair comparison
true_labels = sample_df["sentiment"].str.lower()
original_preds = sample_df["llm_pred"].str.lower()
guarded_preds = sample_df["llm_pred_conf"].str.lower()

print("Original LLM Accuracy:",
      accuracy_score(true_labels, original_preds))

print("Guarded LLM Accuracy:",
      accuracy_score(true_labels, guarded_preds))

from transformers import pipeline

sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model="ProsusAI/finbert"
)

def llm_sentiment_with_confidence(text, threshold=0.6):
    result = sentiment_pipeline(text[:512])[0]

    label = result["label"].lower()
    score = result["score"]

    # Confidence-based guardrail
    if score < threshold:
        return "neutral"

    return label

sample_df["llm_pred_conf"] = sample_df["clean_text"].apply(
    llm_sentiment_with_confidence
)

from sklearn.metrics import accuracy_score

print(
    accuracy_score(
        sample_df["sentiment"].str.lower(),
        sample_df["llm_pred_conf"].str.lower()
    )
)

# One example sentence
example_text = "The company reported strong quarterly profits and increased revenue guidance."

# Raw FinBERT output
raw_output = sentiment_pipeline(example_text)[0]

# Guarded prediction
guarded_pred = llm_sentiment_with_confidence(example_text, threshold=0.6)

print("Text:")
print(example_text)
print("\nRaw LLM Output:")
print(raw_output)
print("\nFinal Guarded Prediction:")
print(guarded_pred)

ambiguous_text = "The company announced updates to its long-term operational strategy."

raw_output = sentiment_pipeline(ambiguous_text)[0]
guarded_pred = llm_sentiment_with_confidence(ambiguous_text, threshold=0.6)

print("Raw:", raw_output)
print("Final:", guarded_pred)

test_positive = [
    "The company reported record profits and strong revenue growth this quarter",
    "Shares surged after the firm announced higher-than-expected earnings",
    "The bank posted excellent financial results and raised its guidance"
]

for text in test_positive:
    print(text)
    print("LLM:", llm_sentiment_with_confidence(text, threshold=0.6))
    print("-"*60)

# ===== Manual Input Test =====

user_input = input("Enter financial news text: ")

raw_output = sentiment_pipeline(user_input)[0]
final_prediction = llm_sentiment_with_confidence(user_input, threshold=0.6)

print("\n--- RESULT ---")
print("Input Text:", user_input)
print("Raw LLM Output:", raw_output)
print("Final Guarded Prediction:", final_prediction)